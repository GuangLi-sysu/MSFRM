{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide four synthetic datasets of increasing number of anomaly subgraphs. Specifically, there are  5, 30, 50 and 100 handcrafted subgraphs in the biggest connected component of transfer graph which contains more than 400,000 nodes. Each sub-graph is a connected community with random number of nodes from 20 to 200. To reduce the influence to algorithms, these subgraphs are controlled to independent and no overlap. Note that risky flows are generated within subgraphs, and the number is controlled on the 1/10 of the nodes of sub-graph. For example, generated sub-graph with 100 nodes have 10 flows. The code of generating synthetic dataset is presented at file gen_synthetic.py. A brief description of this synthetic datasets:\n",
    "\n",
    "| Datasets   | S5      | S30     | S50     | S100    |\n",
    "|------------|---------|---------|---------|---------|\n",
    "| #subgraphs | 5       | 30      | 50      | 100     |\n",
    "| #paths     | 33      | 272     | 429     | 651     |\n",
    "| #nodes     | 477010  | 477010  | 477010  | 477010  |\n",
    "| #edges     | 1066772 | 1067818 | 1068448 | 1069369 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import msfrm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_data(name):\n",
    "    with open(f'../dataset_syn/{name}_data.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        label_subgraphs = data['subgraphs']\n",
    "        label_paths = data['paths']\n",
    "        label_paths_ = []\n",
    "        for subgraph in label_paths:\n",
    "            sub_ = []\n",
    "            for path in subgraph:\n",
    "                sub_ += path\n",
    "            label_paths_.append(sub_)\n",
    "\n",
    "        n_subgraphs = data['n_subgraphs']\n",
    "        n_paths = data['n_paths']\n",
    "        concat_data = data['concat_data']\n",
    "        source_data = pd.DataFrame(concat_data, columns=['from', 'to', 'date', 'amount'])\n",
    "        source_data = source_data.iloc[:,[0,1,3]]\n",
    "\n",
    "        return [label_subgraphs, label_paths_, n_subgraphs, n_paths, source_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_subgraphs(label_graph, pred_graph):\n",
    "    k = set()\n",
    "    for i in range(len(pred_graph)):\n",
    "        for j in range(len(label_graph)):\n",
    "            if set(pred_graph[i]) & set(label_graph[j]):\n",
    "                k.add(j)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the structure difference between sub-graph and flow, we use hit accuracy as evaluation criteria of detection performance and generate amount-abnormal transactions as target risky transactions in synthetic datasets. Assumed that there are $n$ anomaly subgraphs in a transaction network, $m$ abnormal flows in these $n$ subgraphs, $n_{hit}$ describes how many anomaly subgraphs are hit in the top $n$ dense subgraphs outputted by subgraph-based algorithm or in the top $m$ dense flows outputted by our algorithm. We use $N_{pred}$ to represent the node set of algorithm outputs and $N_{truth}^i$ to represent the node set of the $i$th known anomaly subgraph. Finally, hit accuracy is defined as:\n",
    "\\begin{align}\n",
    "    \\text{accuracy} &= \\frac{n_{hit}}{n} \\\\\n",
    "    n_{hit} = \\sum_{i=1}^{n} & \\mathbf{I}(N_{truth}^{i} \\cap N_{pred})\n",
    "\\end{align}\n",
    "where $\\mathbf{I}$ is indicator function. $\\mathbf{I}=1$ when $N_{truth}^{i} \\cap N_{pred} \\neq \\emptyset$, otherwise $\\mathbf{I}=0$. Intuitively, hit accuracy is measured by the ratio between the number of hit subgraphs and total anomaly subgraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector initializing successful! Max score is 519035096.021601, subgraph is [411696, 71911].\n",
      "!!!!!!!!!!!!!!\n",
      "\n",
      "Max score update: 830452836.522721! Flow is [411696, 71911, 233915].\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = ['random5', 'random30', 'random50', 'random100']\n",
    "\n",
    "for name in synthetic_data:\n",
    "    data = r_data(name)\n",
    "    k = data[3]\n",
    "    output = msfrm.msfrm(data[4], k)\n",
    "    hit_graphs = hit_subgraphs(data[0], [i[1] for i in output])\n",
    "    n_hit = len(hit_graphs)\n",
    "    accuracy = n_hit / data[2]\n",
    "    print(f'Hit accuracy of {name} is {accuracy}!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
